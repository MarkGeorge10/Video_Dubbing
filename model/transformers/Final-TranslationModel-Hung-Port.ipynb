{
 "cells": [
  {
   "cell_type": "code",
   "id": "a5ea71f8f659c4ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:08:45.774368Z",
     "start_time": "2025-04-21T05:08:39.779331Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from huggingface_hub.keras_mixin import keras\n",
    "from sentencepiece import SentencePieceProcessor\n",
    "from transformers import BertTokenizer, TFAutoModelForSeq2SeqLM, TFMarianMTModel, MarianTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-21T05:08:58.624996Z",
     "start_time": "2025-04-21T05:08:58.218527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "eng_hung = pd.read_csv('/Users/tylerglaze/Documents/PSU/AI 574/LanguageDetector/SenPairs-Eng-Hung.tsv', sep='\\t', header=None)\n",
    "eng_hung = eng_hung.rename(columns={1: 'eng', 3: 'hung'})\n",
    "eng_hung.drop([0, 2], axis=1, inplace=True)\n",
    "eng_hung.head()\n",
    "eng_hung.to_csv('eng_hung.csv', index=False)\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:09:00.134683Z",
     "start_time": "2025-04-21T05:09:00.131923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Built with Apple Silicon support:\", tf.config.list_physical_devices('GPU'))"
   ],
   "id": "ac70791d606d4b9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "Built with Apple Silicon support: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:09:01.615738Z",
     "start_time": "2025-04-21T05:09:01.608670Z"
    }
   },
   "cell_type": "code",
   "source": "eng_hung.head()",
   "id": "8e70315650386a97",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                          eng                   hung\n",
       "0      I have to go to sleep.    Aludni kell mennem.\n",
       "1          Muiriel is 20 now.  Muriel immár 20 éves.\n",
       "2          Muiriel is 20 now.  Muiriel most 20 éves.\n",
       "3  The password is \"Muiriel\".     A jelszó: Muiriel.\n",
       "4  The password is \"Muiriel\".     A jelszó \"Muriel\"."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>hung</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have to go to sleep.</td>\n",
       "      <td>Aludni kell mennem.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Muiriel is 20 now.</td>\n",
       "      <td>Muriel immár 20 éves.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Muiriel is 20 now.</td>\n",
       "      <td>Muiriel most 20 éves.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The password is \"Muiriel\".</td>\n",
       "      <td>A jelszó: Muiriel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The password is \"Muiriel\".</td>\n",
       "      <td>A jelszó \"Muriel\".</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:09:03.279803Z",
     "start_time": "2025-04-21T05:09:03.222396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eng_hung.head()\n",
    "eng_hung.dropna()\n",
    "# drop duplicates from each column\n",
    "eng_hung = eng_hung.drop_duplicates(subset=['eng'])\n",
    "eng_hung = eng_hung.drop_duplicates(subset=['hung'])\n",
    "eng_hung.dropna()"
   ],
   "id": "6826fb2181efb60a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                      eng  \\\n",
       "0                                  I have to go to sleep.   \n",
       "1                                      Muiriel is 20 now.   \n",
       "3                              The password is \"Muiriel\".   \n",
       "5                                 I was in the mountains.   \n",
       "6                       You're in better shape than I am.   \n",
       "...                                                   ...   \n",
       "175841  If he was a dictator, you'd be sucking up to him.   \n",
       "175842  How can we calculate the Earth's speed if we d...   \n",
       "175843                                How we doing today?   \n",
       "175844                               Mary can do a split.   \n",
       "175846                          Koko is a female gorilla.   \n",
       "\n",
       "                                                     hung  \n",
       "0                                     Aludni kell mennem.  \n",
       "1                                   Muriel immár 20 éves.  \n",
       "3                                      A jelszó: Muiriel.  \n",
       "5                                     A hegyekben voltam.  \n",
       "6                            Jobb formában vagy, mint én.  \n",
       "...                                                   ...  \n",
       "175841        Ha diktátor lenne ő, benyalnád magad hozzá.  \n",
       "175842  Honnan tudjuk kiszámolni a Föld haladási sebes...  \n",
       "175843                                   Hogy vagyunk ma?  \n",
       "175844                 Mari meg tudja csinálni a spárgát.  \n",
       "175846                              Koko nőstény gorilla.  \n",
       "\n",
       "[136240 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>hung</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have to go to sleep.</td>\n",
       "      <td>Aludni kell mennem.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Muiriel is 20 now.</td>\n",
       "      <td>Muriel immár 20 éves.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The password is \"Muiriel\".</td>\n",
       "      <td>A jelszó: Muiriel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I was in the mountains.</td>\n",
       "      <td>A hegyekben voltam.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>You're in better shape than I am.</td>\n",
       "      <td>Jobb formában vagy, mint én.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175841</th>\n",
       "      <td>If he was a dictator, you'd be sucking up to him.</td>\n",
       "      <td>Ha diktátor lenne ő, benyalnád magad hozzá.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175842</th>\n",
       "      <td>How can we calculate the Earth's speed if we d...</td>\n",
       "      <td>Honnan tudjuk kiszámolni a Föld haladási sebes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175843</th>\n",
       "      <td>How we doing today?</td>\n",
       "      <td>Hogy vagyunk ma?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175844</th>\n",
       "      <td>Mary can do a split.</td>\n",
       "      <td>Mari meg tudja csinálni a spárgát.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175846</th>\n",
       "      <td>Koko is a female gorilla.</td>\n",
       "      <td>Koko nőstény gorilla.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136240 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "da12fb201f54644a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T02:52:35.397638Z",
     "start_time": "2025-04-21T02:52:35.391337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TFAutoModelForSeq2SeqLM, MarianTokenizer, create_optimizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def train_translation_model(model_name, data_df, src_col, tgt_col, save_path):\n",
    "    '''\n",
    "    This function accepts a model name and a data frame and returns a trained model.\n",
    "    :param model_name: the name of the marian model\n",
    "    :param data_df: cleaned data frame of english and hungarian\n",
    "    :param src_col: the name of the column in the df that contains the english sentence\n",
    "    :param tgt_col: the name of the column in the df that contains the hungarian sentence\n",
    "    :param save_path: the path to save the model\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "\n",
    "    # Load model & tokenizer\n",
    "    model = TFAutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Sample down for quicker training during testing, comment out for full dataset\n",
    "    data_df = data_df.sample(frac=0.5)\n",
    "\n",
    "    # Train/validation split, (90, 10)\n",
    "    train_df, val_df = train_test_split(data_df, test_size=0.1)\n",
    "\n",
    "    # Tokenize input/output\n",
    "    def tokenize(df):\n",
    "        '''\n",
    "        This function accepts a data frame and returns tokenized inputs and labels\n",
    "        :param df:\n",
    "        :return:\n",
    "        '''\n",
    "        # Tokenize inputs\n",
    "        inputs = tokenizer(df[src_col].tolist(), return_tensors='tf', padding='max_length',\n",
    "                           truncation=True, max_length=64)\n",
    "        # Tokenize targets\n",
    "        targets = tokenizer(df[tgt_col].tolist(), return_tensors='tf', padding='max_length',\n",
    "                            truncation=True, max_length=64)\n",
    "        # Create labels\n",
    "        labels = targets['input_ids'].numpy()\n",
    "        # Replace pad token with -100\n",
    "        labels[labels == tokenizer.pad_token_id] = -100\n",
    "        # Return inputs and labels as tensors\n",
    "        return inputs, tf.convert_to_tensor(labels)\n",
    "\n",
    "    # Tokenize inputs and labels\n",
    "    train_inputs, train_labels = tokenize(train_df)\n",
    "    # Tokenize inputs and labels\n",
    "    val_inputs, val_labels = tokenize(val_df)\n",
    "\n",
    "    # Optimizer setup\n",
    "    # Steps per epoch\n",
    "    steps_per_epoch = len(train_df) // 16\n",
    "    # Define number of training steps\n",
    "    num_train_steps = steps_per_epoch * 5\n",
    "    # Define optimizer, use Adam, learning rate of 2e-5, no warmup\n",
    "    optimizer, _ = create_optimizer(init_lr=3e-5, num_train_steps=num_train_steps, num_warmup_steps=0)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=optimizer)\n",
    "\n",
    "    # Train\n",
    "    model.fit(\n",
    "        # Input, labels, batch size, epochs\n",
    "        x={ 'input_ids': train_inputs['input_ids'], 'attention_mask': train_inputs['attention_mask'] },\n",
    "        y=train_labels,\n",
    "        validation_data=(\n",
    "            { 'input_ids': val_inputs['input_ids'], 'attention_mask': val_inputs['attention_mask'] },\n",
    "            val_labels\n",
    "        ),\n",
    "        batch_size=32,\n",
    "        epochs=10\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "\n",
    "    return model, tokenizer"
   ],
   "id": "60bbc06db7b8508b",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T04:46:04.662944Z",
     "start_time": "2025-04-21T02:52:38.043589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model, tokenizer = train_translation_model(\n",
    "    model_name='Helsinki-NLP/opus-mt-en-hu',\n",
    "    data_df=eng_hung,\n",
    "    src_col='eng',\n",
    "    tgt_col='hung',\n",
    "    save_path='translation_model-en-hu'\n",
    ")"
   ],
   "id": "3ee53cfeef30e811",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-hu.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x5e8604230>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/ops/map_fn.py\", line 497, in map_fn\n",
      "    _, r_a = while_loop.while_loop(  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/ops/while_loop.py\", line 488, in while_loop\n",
      "    loop_vars = body(*loop_vars)  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/ops/while_loop.py\", line 479, in <lambda>\n",
      "    body = lambda i, lv: (i + 1, orig_body(*lv))  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/ops/map_fn.py\", line 495, in compute\n",
      "    return (i + 1, tas)  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x5e8604230>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/ops/map_fn.py\", line 497, in map_fn\n",
      "    _, r_a = while_loop.while_loop(  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/ops/while_loop.py\", line 488, in while_loop\n",
      "    loop_vars = body(*loop_vars)  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/ops/while_loop.py\", line 479, in <lambda>\n",
      "    body = lambda i, lv: (i + 1, orig_body(*lv))  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/ops/map_fn.py\", line 495, in compute\n",
      "    return (i + 1, tas)  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x3d004ad80>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/ops/map_fn.py\", line 497, in map_fn\n",
      "    _, r_a = while_loop.while_loop(  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/ops/while_loop.py\", line 488, in while_loop\n",
      "    loop_vars = body(*loop_vars)  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/ops/while_loop.py\", line 479, in <lambda>\n",
      "    body = lambda i, lv: (i + 1, orig_body(*lv))  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/ops/map_fn.py\", line 495, in compute\n",
      "    return (i + 1, tas)  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x3d004ad80>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/ops/map_fn.py\", line 497, in map_fn\n",
      "    _, r_a = while_loop.while_loop(  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/ops/while_loop.py\", line 488, in while_loop\n",
      "    loop_vars = body(*loop_vars)  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/ops/while_loop.py\", line 479, in <lambda>\n",
      "    body = lambda i, lv: (i + 1, orig_body(*lv))  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/ops/map_fn.py\", line 495, in compute\n",
      "    return (i + 1, tas)  File \"/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1745203986.723000 3073522 meta_optimizer.cc:967] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1916/1916 [==============================] - 724s 363ms/step - loss: 1.5233 - val_loss: 0.9342\n",
      "Epoch 2/10\n",
      "1916/1916 [==============================] - 681s 355ms/step - loss: 0.8826 - val_loss: 0.7761\n",
      "Epoch 3/10\n",
      "1916/1916 [==============================] - 684s 356ms/step - loss: 0.7081 - val_loss: 0.7150\n",
      "Epoch 4/10\n",
      "1916/1916 [==============================] - 671s 350ms/step - loss: 0.6044 - val_loss: 0.6898\n",
      "Epoch 5/10\n",
      "1916/1916 [==============================] - 669s 349ms/step - loss: 0.5336 - val_loss: 0.6757\n",
      "Epoch 6/10\n",
      "1916/1916 [==============================] - 673s 351ms/step - loss: 0.4808 - val_loss: 0.6647\n",
      "Epoch 7/10\n",
      "1916/1916 [==============================] - 677s 353ms/step - loss: 0.4406 - val_loss: 0.6630\n",
      "Epoch 8/10\n",
      "1916/1916 [==============================] - 668s 349ms/step - loss: 0.4099 - val_loss: 0.6615\n",
      "Epoch 9/10\n",
      "1916/1916 [==============================] - 671s 350ms/step - loss: 0.3883 - val_loss: 0.6605\n",
      "Epoch 10/10\n",
      "1916/1916 [==============================] - 672s 350ms/step - loss: 0.3733 - val_loss: 0.6609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tylerglaze/tf-macos-env/lib/python3.12/site-packages/transformers/configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[62521]]}\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:09:34.829322Z",
     "start_time": "2025-04-21T05:09:33.383685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load model and tokenizer\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained('translation_model-en-hu')\n",
    "tokenizer = MarianTokenizer.from_pretrained('translation_model-en-hu')"
   ],
   "id": "83453131bf35426d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 01:09:33.400564: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2025-04-21 01:09:33.400597: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2025-04-21 01:09:33.400604: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745212173.400974 3462343 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1745212173.401019 3462343 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
      "\n",
      "All the layers of TFMarianMTModel were initialized from the model checkpoint at translation_model-en-hu.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:09:42.115556Z",
     "start_time": "2025-04-21T05:09:42.112587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def translate_text(text, model, tokenizer, max_length=64, num_beams=5):\n",
    "    '''\n",
    "    This function accepts text and returns a translation using a trained model.\n",
    "    :param text: The text to translate\n",
    "    :param model: The trained model to use for translation\n",
    "    :param tokenizer: The tokenizer to use for tokenization that was trained with the model\n",
    "    :param max_length: the maximum length of the translation\n",
    "    :param num_beams: the number of beams to use in the beam search\n",
    "    :return:the translated text\n",
    "    '''\n",
    "    # Tokenize the input text\n",
    "    input_ids = tokenizer(text, return_tensors='tf', padding=True, truncation=True, max_length=max_length)['input_ids']\n",
    "\n",
    "    # Generate prediction\n",
    "    outputs = model.generate(input_ids, max_length=max_length, num_beams=num_beams, early_stopping=True)\n",
    "\n",
    "    # Decode and return the translated text\n",
    "    translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return translated_text"
   ],
   "id": "a8d82efb4546882e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:09:48.324911Z",
     "start_time": "2025-04-21T05:09:44.315277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test out the model on a sample sentence\n",
    "sample_sentence = \"How many people like cats?\"\n",
    "translated = translate_text(sample_sentence, model, tokenizer)\n",
    "print(\"Translation:\", translated)"
   ],
   "id": "b2cfa2c2fc11a302",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: Hányan szeretik a macskákat?\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T04:47:53.540684Z",
     "start_time": "2025-04-21T04:47:53.533599Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 58,
   "source": [
    "#sample down for testing\n",
    "shortened_eng_hung = eng_hung.sample(frac=0.0001, random_state=25)\n",
    "# Create a list of source and true translations\n",
    "source_sentences = shortened_eng_hung['eng'].tolist()\n",
    "true_translations = shortened_eng_hung['hung'].tolist()\n",
    "# define batch size\n",
    "batch_size = 32\n",
    "# Initialize a list to store predicted translations\n",
    "predicted_translations = []"
   ],
   "id": "92a66107dea1adfa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:10:00.692507Z",
     "start_time": "2025-04-21T05:10:00.688951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def translate_batch(texts, model, tokenizer, max_length=64, num_beams=5):\n",
    "    '''\n",
    "    This function accepts a list of texts and returns a list of translations using a trained model.\n",
    "    :param texts: the texts to translate\n",
    "    :param model: the trained model\n",
    "    :param tokenizer: the trained tokenizer\n",
    "    :param max_length: the maximum length of the translation\n",
    "    :param num_beams: the number of beams to use in the beam search\n",
    "    :return: decoded translations\n",
    "    '''\n",
    "    # Tokenize batch\n",
    "    inputs = tokenizer(texts, return_tensors='tf', padding=True, truncation=True, max_length=max_length)\n",
    "\n",
    "    # Generate predictions, set to outputs\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs['input_ids'],\n",
    "        attention_mask=inputs['attention_mask'],\n",
    "        max_length=max_length,\n",
    "        num_beams=num_beams,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    # Decode outputs\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n"
   ],
   "id": "6636d738abb45c69",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:21:49.356920Z",
     "start_time": "2025-04-21T05:10:08.757440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Sample down for testing\n",
    "shortened_eng_hung = eng_hung.sample(frac=0.002, random_state=26)\n",
    "\n",
    "source_sentences = shortened_eng_hung['eng'].tolist()\n",
    "batch_size = 32\n",
    "\n",
    "# Initialize empty DataFrame\n",
    "translation_results = pd.DataFrame(columns=[\"source\", \"translations\"])\n",
    "\n",
    "# Process in batches\n",
    "for i in tqdm(range(0, len(source_sentences), batch_size)):\n",
    "    batch = source_sentences[i:i+batch_size]\n",
    "    #use the translate batch method\n",
    "    translated_batch = translate_batch(batch, model, tokenizer)\n",
    "\n",
    "    # scoped DataFrame from the batch\n",
    "    batch_df = pd.DataFrame({\n",
    "        \"source\": batch,\n",
    "        \"translations\": translated_batch\n",
    "    })\n",
    "\n",
    "    # Push results to Translation Results\n",
    "    translation_results = pd.concat([translation_results, batch_df], ignore_index=True)"
   ],
   "id": "e365aeeb3a952f97",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [11:40<00:00, 77.83s/it]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:21:52.639010Z",
     "start_time": "2025-04-21T05:21:52.628604Z"
    }
   },
   "cell_type": "code",
   "source": "translation_results",
   "id": "8ec51d2ef3c85782",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                source  \\\n",
       "0                             Stop ordering me around.   \n",
       "1                         Why did Tom go to Australia?   \n",
       "2                     Did you think you could fool me?   \n",
       "3                                       I see someone.   \n",
       "4                        Did you find what you needed?   \n",
       "..                                                 ...   \n",
       "267      The enemy has broken through the castle gate.   \n",
       "268                          I have a lot of pictures.   \n",
       "269                     We must make up for lost time.   \n",
       "270  This is the only guidebook that was recommende...   \n",
       "271                                      I need a car.   \n",
       "\n",
       "                                          translations  \n",
       "0                                   Ne rendelgess már!  \n",
       "1                         Tom miért ment Ausztráliába?  \n",
       "2                     Azt gondoltad, hogy becsaphatsz?  \n",
       "3                                       Látok valakit.  \n",
       "4                            Megtaláltad, ami kellett?  \n",
       "..                                                 ...  \n",
       "267                   Az ellenség betörte a vár kaput.  \n",
       "268                                     Sok képem van.  \n",
       "269               Be kell pórolnunk az elveszett időt.  \n",
       "270  Ez az egyetlen útikönyv, amit ajánlottak nekem...  \n",
       "271                          Szükségem van egy autóra.  \n",
       "\n",
       "[272 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>translations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop ordering me around.</td>\n",
       "      <td>Ne rendelgess már!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why did Tom go to Australia?</td>\n",
       "      <td>Tom miért ment Ausztráliába?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did you think you could fool me?</td>\n",
       "      <td>Azt gondoltad, hogy becsaphatsz?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I see someone.</td>\n",
       "      <td>Látok valakit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did you find what you needed?</td>\n",
       "      <td>Megtaláltad, ami kellett?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>The enemy has broken through the castle gate.</td>\n",
       "      <td>Az ellenség betörte a vár kaput.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>I have a lot of pictures.</td>\n",
       "      <td>Sok képem van.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>We must make up for lost time.</td>\n",
       "      <td>Be kell pórolnunk az elveszett időt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>This is the only guidebook that was recommende...</td>\n",
       "      <td>Ez az egyetlen útikönyv, amit ajánlottak nekem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>I need a car.</td>\n",
       "      <td>Szükségem van egy autóra.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:22:06.095736Z",
     "start_time": "2025-04-21T05:22:05.260527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Add the reference translations to the DataFrame\n",
    "shortened_eng_hung = shortened_eng_hung.reset_index(drop=True)\n",
    "translation_results[\"reference\"] = shortened_eng_hung[\"hung\"]\n",
    "\n",
    "# Calculate BLEU Score\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "\n",
    "# Prepare BLEU inputs\n",
    "references = [[ref.split()] for ref in translation_results[\"reference\"].tolist()]\n",
    "hypotheses = [pred.split() for pred in translation_results[\"translations\"].tolist()]\n",
    "\n",
    "# Compute smoothed BLEU score\n",
    "smoothie = SmoothingFunction().method4\n",
    "bleu_score = corpus_bleu(references, hypotheses, smoothing_function=smoothie)\n",
    "\n",
    "# Print and save BLEU score\n",
    "print(f\"Smoothed BLEU score: {bleu_score:.4f}\")\n",
    "\n",
    "with open(\"bleu_score.txt\", \"w\") as f:\n",
    "    f.write(f\"Smoothed Corpus BLEU score: {bleu_score:.4f}\")"
   ],
   "id": "c50d2df9c8c6a696",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothed BLEU score: 0.3723\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T05:22:12.023925Z",
     "start_time": "2025-04-21T05:22:12.015532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import random\n",
    "\n",
    "# Sampling 20 random rows from translation_results\n",
    "sampled_df = translation_results.sample(n=20, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Smoothing function for sentence-level BLEU\n",
    "smoothie = SmoothingFunction().method4\n",
    "\n",
    "# Iterate and compute\n",
    "for i, row in sampled_df.iterrows():\n",
    "    reference = row[\"reference\"].split()\n",
    "    prediction = row[\"translations\"].split()\n",
    "\n",
    "    bleu = sentence_bleu([reference], prediction, smoothing_function=smoothie)\n",
    "\n",
    "    print(f\"BLEU: {bleu:.4f}\")\n",
    "    print(f\"Source: {row['source']}\")\n",
    "    print(f\"Prediction: {row['translations']}\")\n",
    "    print(f\"Reference: {row['reference']}\")\n",
    "    print(\"-\" * 50)"
   ],
   "id": "df4a174b8bf3a567",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.2118\n",
      "Source: I caught a carp in a net.\n",
      "Prediction: Pontyot fogtam hálóban.\n",
      "Reference: Pontyot fogtam hálóval.\n",
      "--------------------------------------------------\n",
      "BLEU: 0.0726\n",
      "Source: I never really liked them.\n",
      "Prediction: Sosem szerettem őket valóban.\n",
      "Reference: Sosem kedveltem őket igazán.\n",
      "--------------------------------------------------\n",
      "BLEU: 1.0000\n",
      "Source: Tell me where she lives.\n",
      "Prediction: Mondd meg, hol lakik!\n",
      "Reference: Mondd meg, hol lakik!\n",
      "--------------------------------------------------\n",
      "BLEU: 1.0000\n",
      "Source: My house is your house.\n",
      "Prediction: Az én házam a te házad.\n",
      "Reference: Az én házam a te házad.\n",
      "--------------------------------------------------\n",
      "BLEU: 0.0000\n",
      "Source: Shit stinks.\n",
      "Prediction: Bűzlik a szar.\n",
      "Reference: A szar büdös.\n",
      "--------------------------------------------------\n",
      "BLEU: 1.0000\n",
      "Source: Whose number is this?\n",
      "Prediction: Kinek a száma ez?\n",
      "Reference: Kinek a száma ez?\n",
      "--------------------------------------------------\n",
      "BLEU: 0.0000\n",
      "Source: Do you have dinner plans?\n",
      "Prediction: Vacsora terveid vannak?\n",
      "Reference: Megvan már, hogy hol fogsz vacsorázni?\n",
      "--------------------------------------------------\n",
      "BLEU: 0.0000\n",
      "Source: The pressure was tremendous.\n",
      "Prediction: A nyomás szörnyű volt.\n",
      "Reference: Óriási volt a nyomás.\n",
      "--------------------------------------------------\n",
      "BLEU: 0.0000\n",
      "Source: I am as I am.\n",
      "Prediction: Olyan vagyok, mint amilyen.\n",
      "Reference: Ilyen vagyok.\n",
      "--------------------------------------------------\n",
      "BLEU: 0.2118\n",
      "Source: Tom appears to be nervous.\n",
      "Prediction: Tom idegesnek tűnik.\n",
      "Reference: Tom idegesnek látszik.\n",
      "--------------------------------------------------\n",
      "BLEU: 0.2214\n",
      "Source: What does it cost?\n",
      "Prediction: Mennyibe kerül?\n",
      "Reference: Mennyibe kerül?\n",
      "--------------------------------------------------\n",
      "BLEU: 0.2939\n",
      "Source: We must make up for lost time.\n",
      "Prediction: Be kell pórolnunk az elveszett időt.\n",
      "Reference: Be kell pótolnunk az elveszett időt.\n",
      "--------------------------------------------------\n",
      "BLEU: 0.5757\n",
      "Source: We had one chance.\n",
      "Prediction: Egy esélyünk volt.\n",
      "Reference: Egy esélyünk volt.\n",
      "--------------------------------------------------\n",
      "BLEU: 0.0519\n",
      "Source: Do you like cities?\n",
      "Prediction: Szereted a városokat?\n",
      "Reference: Teteszenek neked a városok?\n",
      "--------------------------------------------------\n",
      "BLEU: 0.5757\n",
      "Source: Where is my mother?\n",
      "Prediction: Hol van anyám?\n",
      "Reference: Hol van anyám?\n",
      "--------------------------------------------------\n",
      "BLEU: 0.2939\n",
      "Source: Have you ever seen sausage being made?\n",
      "Prediction: Láttad már, hogy készítik a kolbászt?\n",
      "Reference: Láttad már, hogyan készítik a kolbászt?\n",
      "--------------------------------------------------\n",
      "BLEU: 0.1679\n",
      "Source: Tom is still standing.\n",
      "Prediction: Tom még áll.\n",
      "Reference: Tom még mindig áll.\n",
      "--------------------------------------------------\n",
      "BLEU: 0.1862\n",
      "Source: Tom was in considerable pain.\n",
      "Prediction: Tomnak hatalmas fájdalmai voltak.\n",
      "Reference: Tomnak nagy fájdalmai voltak.\n",
      "--------------------------------------------------\n",
      "BLEU: 0.2178\n",
      "Source: Tom likes to drink chilled water in hot weather, while Mary prefers hers at room temperature.\n",
      "Prediction: Tom meleg időben szeret hideg vizet inni, míg Mary jobban szobahőmérsékletben szereti az övét.\n",
      "Reference: Nagy melegben Tom hideg vizet szeret inni, míg Mary jobban kedveli, ha az övé szobahőmérsékletű.\n",
      "--------------------------------------------------\n",
      "BLEU: 0.0610\n",
      "Source: I hadn't really thought about it.\n",
      "Prediction: Nem igazán gondoltam rá.\n",
      "Reference: Nem nagyon gondolkoztam róla.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
